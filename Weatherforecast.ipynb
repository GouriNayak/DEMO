{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weatherforecast.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7akC5Y56Jf8BFtSC+eZHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GouriNayak/DEMO/blob/main/Weatherforecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmMScs6kc6He"
      },
      "source": [
        "Import the required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygScsLDgbhMk"
      },
      "source": [
        "import numpy as np  # linear algebra\n",
        "import pandas as pd # Data processing , CSV file I/O (e.g. pd.read_csv)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf7lsR46i9uC"
      },
      "source": [
        "Load the csv file as data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pDcimxV48YO"
      },
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/GouriNayak/DEMO/main/weatherAUS.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSlM8PlK6V7t",
        "outputId": "c22772fc-7b59-458b-b936-a9e28d5719d6"
      },
      "source": [
        "print('size of weather data frame is :',df.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of weather data frame is : (142193, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u92SvWhx6gel"
      },
      "source": [
        "Display data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC6mCSD66jat",
        "outputId": "193699bd-bbe2-4357-96b8-d84c7352c0ec"
      },
      "source": [
        "print(df[0:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
            "0  2008-12-01   Albury     13.4  ...         No      0.0            No\n",
            "1  2008-12-02   Albury      7.4  ...         No      0.0            No\n",
            "2  2008-12-03   Albury     12.9  ...         No      0.0            No\n",
            "3  2008-12-04   Albury      9.2  ...         No      1.0            No\n",
            "4  2008-12-05   Albury     17.5  ...         No      0.2            No\n",
            "\n",
            "[5 rows x 24 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8bypx4Y6wSt"
      },
      "source": [
        "Checking null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xpJKf1j67j-",
        "outputId": "17d324b7-2813-49de-cd80-f58e85390462"
      },
      "source": [
        "print(df.count().sort_values())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sunshine          74377\n",
            "Evaporation       81350\n",
            "Cloud3pm          85099\n",
            "Cloud9am          88536\n",
            "Pressure9am      128179\n",
            "Pressure3pm      128212\n",
            "WindDir9am       132180\n",
            "WindGustDir      132863\n",
            "WindGustSpeed    132923\n",
            "WindDir3pm       138415\n",
            "Humidity3pm      138583\n",
            "Temp3pm          139467\n",
            "WindSpeed3pm     139563\n",
            "Humidity9am      140419\n",
            "RainToday        140787\n",
            "Rainfall         140787\n",
            "WindSpeed9am     140845\n",
            "Temp9am          141289\n",
            "MinTemp          141556\n",
            "MaxTemp          141871\n",
            "Date             142193\n",
            "Location         142193\n",
            "RISK_MM          142193\n",
            "RainTomorrow     142193\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pApzDYk17JOs"
      },
      "source": [
        "As we can see the first 4 coloumns have less than 60% data, we can ignore these 4 colur\n",
        "\n",
        "we don't need the location column because we are going to find if it will rain in Australia(not lacation specific)\n",
        "\n",
        "we are going to drop the date column too.\n",
        "\n",
        "we need to remove RISK_MM because we want to predict 'RainTomorrow' and \n",
        "\n",
        "RISK_MM can leak\n",
        "we remove unwanted data\n",
        "'Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date'\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HmW9L-t9sxa"
      },
      "source": [
        "df = df.drop(columns=['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date'],axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R60qmC698JL",
        "outputId": "7d144945-f17a-486c-8917-60592ad9f1d0"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(142193, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQo2cFqm-Ci6"
      },
      "source": [
        "# Let us get rid of all null values in df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoM0QMZb-IFa"
      },
      "source": [
        "df = df.dropna(how='any')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFg8M4qt-QVK",
        "outputId": "6026a8ae-daaa-48d2-9a0e-d8403d7ef8d2"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112925, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx9nIPWi8f7E"
      },
      "source": [
        "its time to remove the outliers in our data - we are using z-score to detect and remove the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4aXCpRi9HUr"
      },
      "source": [
        "from scipy import stats"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UspTj8Cc9Pyk"
      },
      "source": [
        "z=np.abs(stats.zscore(df._get_numeric_data()))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smPXMTxy9trD",
        "outputId": "81050a7f-0c50-4187-9369-df540142c06c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(z)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.11756741 0.10822071 0.20666127 ... 1.14245477 0.08843526 0.04787026]\n",
            " [0.84180219 0.20684494 0.27640495 ... 1.04184813 0.04122846 0.31776848]\n",
            " [0.03761995 0.29277194 0.27640495 ... 0.91249673 0.55672435 0.15688743]\n",
            " ...\n",
            " [1.44940294 0.23548728 0.27640495 ... 0.58223051 1.03257127 0.34701958]\n",
            " [1.16159206 0.46462594 0.27640495 ... 0.25166583 0.78080166 0.58102838]\n",
            " [0.77784422 0.4789471  0.27640495 ... 0.2085487  0.37167606 0.56640283]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FxqVVYa9wZC"
      },
      "source": [
        "df=df[(z<3).all(axis=1)]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goqMD2Jj9zVz",
        "outputId": "7430068e-643c-4704-fac7-97877b6fa6bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(107868, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahk2y97j91cB"
      },
      "source": [
        "lets deal with the categorical cloumns now\n",
        "Simply change yes/no to 1/0 for RainToDay and RainTomorrow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAM6LZYW950b"
      },
      "source": [
        "df['RainToday'].replace(('no:0','yes:1'),inplace = True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dBlBOFt_4NB"
      },
      "source": [
        "df['RainTomorrow'].replace(('no:0','yes:1'),inplace = True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J60c3yesACHP"
      },
      "source": [
        "see unique values and convert them to int using pd.getDummies()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCHF_uJfAGKZ"
      },
      "source": [
        "categorical_columns = ['WindGustDir','WindDir3pm','WindDir9am']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6B6zWkjAWjp",
        "outputId": "61c52bbb-98eb-43be-b34a-6dc7ac552b3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for col in categorical_columns:\n",
        "\tprint(np.unique(df[col]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['E' 'ENE' 'ESE' 'N' 'NE' 'NNE' 'NNW' 'NW' 'S' 'SE' 'SSE' 'SSW' 'SW' 'W'\n",
            " 'WNW' 'WSW']\n",
            "['E' 'ENE' 'ESE' 'N' 'NE' 'NNE' 'NNW' 'NW' 'S' 'SE' 'SSE' 'SSW' 'SW' 'W'\n",
            " 'WNW' 'WSW']\n",
            "['E' 'ENE' 'ESE' 'N' 'NE' 'NNE' 'NNW' 'NW' 'S' 'SE' 'SSE' 'SSW' 'SW' 'W'\n",
            " 'WNW' 'WSW']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1VRmfclAbWq"
      },
      "source": [
        "transform the categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldy9upNpAdR5"
      },
      "source": [
        "df=pd.get_dummies(df,columns=categorical_columns)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGTYWEqrAgc5"
      },
      "source": [
        "next step is to standardize our data using MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1vYslXZAn-R"
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STLv68mRAqch"
      },
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n"
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}